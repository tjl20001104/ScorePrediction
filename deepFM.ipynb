{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FM(nn.Module):\n",
    " \n",
    "    def __init__(self, num_user, num_book, latent_dim, n_hidden_1, n_hidden_2, n_output_1, n_output_2):\n",
    "        \"\"\"\n",
    "        latent_dim: 各个离散特征隐向量的维度\n",
    "        input_shape: 这个最后离散特征embedding之后的拼接和dense拼接的总特征个数\n",
    "        feature_1_user: 用户带bias的embedding vector 1 x latent_dim\n",
    "        feature_1_book: 书带bias的embedding vector 1 x latent_dim\n",
    "        feature_high_user: 用户高阶特征向量 1 x n_output_1\n",
    "        feature_high_book: 书高阶特征向量 1 x n_output_1\n",
    "        \"\"\"\n",
    "        super(FM, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        # 定义三个矩阵， 一个是全局偏置，一个是一阶权重矩阵， 一个是二阶交叉矩阵，注意这里的参数由于是可学习参数，需要用nn.Parameter进行定义\n",
    "        self.bias_user = nn.Parameter(torch.zeros([1, latent_dim]))\n",
    "        self.bias_book = nn.Parameter(torch.zeros([1, latent_dim]))\n",
    "        self.emb_user = nn.Embedding(num_user,latent_dim)\n",
    "        self.emb_book = nn.Embedding(num_book,latent_dim)\n",
    "        self.network_user = nn.Sequential(\n",
    "            nn.Linear(latent_dim, n_hidden_1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden_1, n_output_1)\n",
    "        )\n",
    "        self.network_book = nn.Sequential(\n",
    "            nn.Linear(latent_dim, n_hidden_1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden_1, n_output_1)\n",
    "        )\n",
    "        self.net_similatiry = nn.Sequential(\n",
    "            nn.Linear(2*n_output_1 + 2*latent_dim, n_hidden_2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden_2, n_output_2)\n",
    "        )\n",
    " \n",
    "    def forward(self, inputs):\n",
    "        feature_1_user = self.emb_user(inputs[0][0]) + self.bias_user\n",
    "        feature_1_book = self.emb_book(inputs[0][1]) + self.bias_book\n",
    "\n",
    "        feature_high_user = self.network_user(feature_1_user)\n",
    "        feature_high_book = self.network_book(feature_1_book)\n",
    "\n",
    "        feature_all = torch.cat([feature_1_user, feature_1_book, feature_high_user, feature_high_book],1)\n",
    "        score = self.net_similatiry(feature_all)\n",
    "\n",
    "        return score\n",
    "\n",
    "    def params(self):\n",
    "        params = [self.bias_user,\n",
    "                  self.bias_book,\n",
    "                  self.emb_user.parameters(),\n",
    "                  self.emb_book.parameters(),\n",
    "                  self.network_user.parameters(),\n",
    "                  self.network_book.parameters(),\n",
    "                  self.net_similatiry.parameters()]\n",
    "        return filter(lambda p: p.requires_grad, chain(*params))\n",
    "\n",
    "\n",
    "class Ratingdataset(Dataset):\n",
    "    def __init__(self, data_path, batch_size, user2idx, book2idx):\n",
    "        df = pd.read_csv(data_path, header=None, index_col=None)\n",
    "        df = df.drop_duplicates()\n",
    "        self.data = df.values\n",
    "        self.batch_size = batch_size\n",
    "        self.user2idx = user2idx\n",
    "        self.book2idx = book2idx\n",
    "        self._len = df.shape[1]\n",
    "\n",
    "    def __getitem__(self, id_index):\n",
    "        user_idx = self.data[id_index,0]\n",
    "        book_idx = self.data[id_index,1]\n",
    "        rate = self.data[id_index,2]\n",
    "        return user_idx,book_idx,rate\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.read_csv(\"Ratings.csv\",header=0,index_col=None)\n",
    "df_all = df_all.drop_duplicates()\n",
    "user_all = df_all.iloc[:,0].unique().tolist()\n",
    "user2idx = {}\n",
    "book_all = df_all.iloc[:,1].unique().tolist()\n",
    "book2idx = {}\n",
    "for i in range(len(user_all)):\n",
    "    user2idx[user_all[i]] = i\n",
    "for i in range(len(book_all)):\n",
    "    book2idx[book_all[i]] = i\n",
    "\n",
    "dataset_train = Ratingdataset(\"train_ratings.csv\", 1000, user2idx, book2idx)\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=dataset_train.batch_size, shuffle=True)\n",
    "\n",
    "dataset_test = Ratingdataset(\"test_ratings.csv\", 1000, user2idx, book2idx)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=dataset_test.batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], grad_fn=<UnbindBackward0>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], grad_fn=<UnbindBackward0>)\n",
      "Parameter containing:\n",
      "tensor([[-0.6580, -1.7045,  0.0101,  ...,  0.5670, -1.7790,  1.0079],\n",
      "        [-1.1239,  0.9299,  1.1763,  ...,  0.0393, -0.2003, -0.0424],\n",
      "        [-1.5861, -1.3449,  0.7975,  ...,  1.2174,  0.1756,  1.0776],\n",
      "        ...,\n",
      "        [-0.5011, -0.5798, -3.3838,  ..., -0.2615,  0.1853,  1.0054],\n",
      "        [-0.8662, -0.3798,  0.2826,  ...,  0.3964,  0.2013,  0.4617],\n",
      "        [-1.7459, -1.3349,  1.4855,  ...,  1.1347,  1.6745, -0.4227]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.4074, -0.4054, -1.7345,  ..., -1.2279, -0.4757, -0.8833],\n",
      "        [-0.4617,  0.1998, -0.4527,  ...,  0.4166, -0.1888,  1.2097],\n",
      "        [-0.2451, -1.7706, -1.6488,  ...,  1.5842,  0.0669, -0.6910],\n",
      "        ...,\n",
      "        [-1.2620, -2.1057, -1.5332,  ...,  0.5242, -0.7201, -1.2579],\n",
      "        [-0.6335, -0.2119,  0.8291,  ..., -0.6111, -1.1844, -0.9060],\n",
      "        [ 0.2690,  1.1616,  0.4608,  ..., -0.3128, -1.0042, -1.5488]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0812,  0.0897, -0.0641,  ..., -0.1202, -0.0867, -0.0791],\n",
      "        [-0.1117,  0.0046,  0.0043,  ..., -0.0645, -0.0190, -0.1373],\n",
      "        [ 0.0446, -0.0523,  0.1228,  ...,  0.0757, -0.1142, -0.0434],\n",
      "        ...,\n",
      "        [-0.0727,  0.0542, -0.0727,  ..., -0.1322, -0.0187, -0.1219],\n",
      "        [-0.1398,  0.1263, -0.0149,  ..., -0.0773,  0.1005,  0.0447],\n",
      "        [-0.1317, -0.0798, -0.0784,  ...,  0.1094,  0.0930, -0.1141]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0704, -0.0910, -0.0614,  0.0947,  0.1172, -0.1393, -0.0876,  0.0828,\n",
      "        -0.0750, -0.0283, -0.1037, -0.0480,  0.0335, -0.0978, -0.0054, -0.0167,\n",
      "         0.1376, -0.0673, -0.0559,  0.0059, -0.0981,  0.0231, -0.1057,  0.0749,\n",
      "         0.1315, -0.0570, -0.1051, -0.0525,  0.1332, -0.0615,  0.0937,  0.0245,\n",
      "         0.1223, -0.0700, -0.0078, -0.0563,  0.0342,  0.0525, -0.0373, -0.0856,\n",
      "         0.0229, -0.0530,  0.0242, -0.1139, -0.0915, -0.0021,  0.0322,  0.0171,\n",
      "         0.1172,  0.1154], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0267,  0.1007,  0.1179,  ..., -0.0030,  0.0998, -0.0983],\n",
      "        [ 0.0258, -0.0857, -0.0894,  ...,  0.1022, -0.1004, -0.1110],\n",
      "        [-0.0090,  0.1174, -0.0802,  ..., -0.0640, -0.0976, -0.0781],\n",
      "        ...,\n",
      "        [ 0.1408, -0.0720,  0.0146,  ...,  0.0833, -0.0685, -0.0947],\n",
      "        [-0.1161, -0.1142,  0.0503,  ..., -0.0882, -0.0732,  0.1269],\n",
      "        [ 0.0186,  0.0947, -0.0762,  ..., -0.0960,  0.1113,  0.0514]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.1273,  0.1020, -0.0362, -0.0090, -0.0777,  0.0073,  0.0311, -0.1369,\n",
      "        -0.0108,  0.0340, -0.0727, -0.1017, -0.0022,  0.0892,  0.1294, -0.0273,\n",
      "         0.0333,  0.0026,  0.0562,  0.0554,  0.0553,  0.0544,  0.0310,  0.1057,\n",
      "        -0.0246], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.1334, -0.1366,  0.0069,  ..., -0.1347,  0.0050, -0.0538],\n",
      "        [ 0.0909,  0.0620,  0.0269,  ...,  0.1310,  0.0644,  0.0613],\n",
      "        [-0.0846, -0.1382,  0.0681,  ..., -0.0382, -0.1072,  0.1206],\n",
      "        ...,\n",
      "        [-0.0418,  0.0193,  0.0409,  ..., -0.0810,  0.0947, -0.1287],\n",
      "        [-0.0094,  0.0520,  0.0424,  ..., -0.0484,  0.0130, -0.0267],\n",
      "        [ 0.0546, -0.0822,  0.1331,  ...,  0.1074,  0.0050,  0.0930]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.1126,  0.1102,  0.0559,  0.0747,  0.0769,  0.0025,  0.0034,  0.0889,\n",
      "        -0.0922, -0.1074,  0.0898, -0.0006,  0.0989,  0.0449,  0.0401, -0.0222,\n",
      "        -0.0414,  0.0376, -0.0736,  0.1278, -0.0199,  0.0751, -0.0754,  0.1191,\n",
      "         0.1111, -0.0904,  0.0762,  0.1371,  0.1268,  0.0476, -0.1383, -0.0413,\n",
      "         0.0365,  0.0535,  0.0150, -0.0328, -0.1040, -0.1194, -0.0713,  0.0979,\n",
      "         0.0098, -0.0244, -0.1207,  0.0977,  0.0650,  0.0372, -0.0261, -0.0209,\n",
      "         0.0012,  0.0181], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0884, -0.0871,  0.1176,  ...,  0.0296,  0.0757, -0.0896],\n",
      "        [-0.1254,  0.0678, -0.1099,  ...,  0.0904,  0.0411,  0.0143],\n",
      "        [ 0.1181,  0.0767,  0.1291,  ...,  0.0358, -0.0048, -0.0959],\n",
      "        ...,\n",
      "        [ 0.0747,  0.0948, -0.0201,  ..., -0.0516, -0.0998,  0.1408],\n",
      "        [-0.0016,  0.0779,  0.1069,  ..., -0.0017, -0.0445,  0.1330],\n",
      "        [ 0.1287,  0.0495, -0.0294,  ...,  0.0338,  0.0189,  0.0090]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0439,  0.0180,  0.1301,  0.0799, -0.0068,  0.0441,  0.0256, -0.1247,\n",
      "         0.0414,  0.1116, -0.1058, -0.0413, -0.0420,  0.0411, -0.0431,  0.1178,\n",
      "        -0.0648, -0.1261,  0.0398, -0.0004, -0.0410, -0.0697,  0.0920, -0.1299,\n",
      "         0.1153], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0192, -0.0472,  0.0276,  ...,  0.0093, -0.0328,  0.0198],\n",
      "        [-0.0679,  0.0169, -0.0461,  ...,  0.0736,  0.0326, -0.0431],\n",
      "        [-0.0290, -0.0477,  0.0282,  ..., -0.0529,  0.0330,  0.0196],\n",
      "        ...,\n",
      "        [-0.0530,  0.0091, -0.0345,  ...,  0.0247, -0.0396, -0.0218],\n",
      "        [-0.0444,  0.0220, -0.0627,  ...,  0.0610,  0.0633, -0.0411],\n",
      "        [ 0.0726,  0.0204,  0.0443,  ..., -0.0204,  0.0468,  0.0072]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0154,  0.0186,  0.0322, -0.0661,  0.0737,  0.0433,  0.0334,  0.0049,\n",
      "         0.0670, -0.0545, -0.0082,  0.0197, -0.0245, -0.0784, -0.0396,  0.0501,\n",
      "         0.0667,  0.0616, -0.0079, -0.0535, -0.0374,  0.0122, -0.0542, -0.0523,\n",
      "         0.0118,  0.0653,  0.0411, -0.0548,  0.0450, -0.0018],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.1096, -0.0220, -0.1452,  0.0786,  0.0598, -0.0664, -0.0789,  0.0297,\n",
      "         -0.1212, -0.0982,  0.0501,  0.0392, -0.1343, -0.0135, -0.0816,  0.0492,\n",
      "         -0.1002, -0.1209,  0.0727,  0.1598,  0.0983, -0.0170,  0.1550, -0.1222,\n",
      "          0.0023, -0.0476, -0.1637,  0.0921, -0.0875,  0.1313],\n",
      "        [-0.0948,  0.0085,  0.0096,  0.1284, -0.0301,  0.1539, -0.1265,  0.1080,\n",
      "          0.1649,  0.1588,  0.1761, -0.1308, -0.0162,  0.0539,  0.1207, -0.1395,\n",
      "         -0.0837,  0.0659,  0.1654,  0.0256,  0.1192,  0.0246, -0.1402, -0.0848,\n",
      "         -0.1449, -0.1300,  0.1539,  0.1068,  0.1537, -0.1801],\n",
      "        [ 0.1614, -0.1609, -0.1663,  0.1135,  0.0627, -0.0249, -0.1282,  0.1567,\n",
      "         -0.1232,  0.0989, -0.0109,  0.1387, -0.0652, -0.1038,  0.1729, -0.0657,\n",
      "         -0.0883,  0.1325, -0.0398,  0.1071,  0.0945,  0.0167, -0.0219,  0.0360,\n",
      "         -0.0291, -0.0436, -0.1709, -0.0058,  0.1751, -0.1580],\n",
      "        [ 0.1698,  0.1335, -0.0538, -0.1435, -0.1749,  0.1126, -0.0217, -0.0139,\n",
      "         -0.0395,  0.0181, -0.0410, -0.1623, -0.0981, -0.0949, -0.1164, -0.0386,\n",
      "         -0.0675, -0.1110, -0.0249, -0.0556, -0.1501,  0.1710, -0.1729, -0.0358,\n",
      "          0.1255,  0.0258,  0.0945, -0.1437, -0.1524, -0.0062],\n",
      "        [-0.0101, -0.1330,  0.1783,  0.1738,  0.0711,  0.0725, -0.1490, -0.1102,\n",
      "         -0.0060, -0.0090,  0.1571, -0.0541, -0.0048, -0.1146,  0.0987,  0.1034,\n",
      "          0.1589,  0.0539,  0.0704, -0.1697,  0.1146, -0.0820, -0.0941, -0.1780,\n",
      "          0.0556,  0.1492, -0.1290, -0.0483,  0.0563, -0.1083],\n",
      "        [ 0.0496,  0.0557,  0.1491,  0.0175,  0.1687, -0.0482,  0.0337, -0.0117,\n",
      "         -0.0840,  0.1281,  0.0120,  0.0094,  0.0380, -0.1172, -0.1560, -0.1773,\n",
      "         -0.0337, -0.0313, -0.0805,  0.0119,  0.1761, -0.0991, -0.1072,  0.1710,\n",
      "          0.0437, -0.1466,  0.0521, -0.0532,  0.0639,  0.0316],\n",
      "        [ 0.0448,  0.1133, -0.0736,  0.1656,  0.0748, -0.1750, -0.1566,  0.0786,\n",
      "          0.0377,  0.1558, -0.1578,  0.0455,  0.1561, -0.1113, -0.0211,  0.0829,\n",
      "          0.1305,  0.0909,  0.0042,  0.1322, -0.1412,  0.0624, -0.0015, -0.0048,\n",
      "          0.0520,  0.1822,  0.0625, -0.1353,  0.0349,  0.0706],\n",
      "        [-0.0991,  0.0627,  0.0273, -0.1652, -0.0254, -0.0489, -0.1336,  0.1272,\n",
      "         -0.1673,  0.0980, -0.1416, -0.0727,  0.0136, -0.0126, -0.1361, -0.0962,\n",
      "         -0.1738,  0.1055,  0.0321, -0.1354, -0.0843,  0.1330,  0.1640,  0.0814,\n",
      "          0.1797,  0.0076,  0.0670,  0.1350,  0.0994,  0.0637],\n",
      "        [ 0.0444,  0.1531, -0.1329,  0.1229,  0.0257, -0.0399, -0.1455, -0.0090,\n",
      "          0.0090, -0.1664, -0.0653, -0.1397, -0.0763, -0.0419,  0.1410,  0.1479,\n",
      "          0.0645, -0.1557,  0.0058, -0.1540, -0.1296, -0.0281,  0.1178, -0.1598,\n",
      "         -0.1297, -0.0909,  0.0600,  0.0904,  0.0592, -0.0938],\n",
      "        [-0.1465,  0.0910,  0.0353,  0.1022,  0.1215, -0.1673,  0.0177, -0.1798,\n",
      "          0.1456, -0.0930,  0.1018,  0.0522, -0.0481, -0.1505,  0.1334, -0.1451,\n",
      "         -0.0988,  0.0411, -0.0254,  0.0649, -0.1669, -0.0166,  0.0222, -0.0364,\n",
      "          0.0481, -0.1015, -0.1597, -0.1584, -0.1325, -0.0597],\n",
      "        [ 0.1197,  0.1454,  0.1619,  0.1685,  0.1811,  0.0838,  0.0186,  0.1680,\n",
      "          0.0524,  0.1187,  0.1744, -0.0916, -0.1051,  0.1147, -0.1557, -0.0744,\n",
      "          0.1224,  0.1722, -0.1305,  0.0721, -0.0265,  0.0167,  0.1814, -0.1446,\n",
      "          0.1335,  0.0235, -0.0760,  0.1088,  0.0614,  0.0057]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1338, -0.0619, -0.0307, -0.0395, -0.0152,  0.1109, -0.0106, -0.0823,\n",
      "        -0.1124, -0.1705, -0.1171], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "epoch = 100\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = FM(len(user2idx), len(book2idx), latent_dim=50, n_hidden_1=50, n_hidden_2=30, n_output_1=25, n_output_2=11)\n",
    "\n",
    "for para in model.params():\n",
    "    print(para)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('rl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2f03c2e53c2de8d89107482e494ddf5359a3bf2badf5e442cb5ba501e9935b09"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
